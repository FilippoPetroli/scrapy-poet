===============
Getting started
===============

The goal of this project is to make reusable Page Objects that separates
extraction logic from crawling. They could be easily tested and distributed
across different projects. Also, they could make use of different backends,
for example, acquiring data from Splash and Auto Extract API.

This project easily integrates Page Objects created using `web-poet`_ with
Scrapy through the configuration of a dependency injection middleware.

Please, see also our :ref:`intro-install` and our :ref:`intro-tutorial`
for a quick start.

License is BSD 3-clause.

.. _`web-poet`: https://github.com/scrapinghub/web-poet
